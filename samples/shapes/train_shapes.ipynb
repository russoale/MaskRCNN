{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mask R-CNN - Train on Shapes Dataset\n",
    "\n",
    "\n",
    "This notebook shows how to train Mask R-CNN on your own dataset. To keep things simple we use a synthetic dataset of shapes (squares, triangles, and circles) which enables fast training. You'd still need a GPU, though, because the network backbone is a Resnet101, which would be too slow to train on a CPU. On a GPU, you can start to get okay-ish results in a few minutes, and good results in less than an hour.\n",
    "\n",
    "The code of the *Shapes* dataset is included below. It generates images on the fly, so it doesn't require downloading any data. And it can generate images of any size, so we pick a small image size to train faster. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import math\n",
    "import re\n",
    "import time\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Root directory of the project\n",
    "ROOT_DIR = os.path.abspath(\"../../\")\n",
    "\n",
    "# Import Mask RCNN\n",
    "sys.path.append(ROOT_DIR)  # To find local version of the library\n",
    "from mrcnn.config import Config\n",
    "from mrcnn import utils\n",
    "import mrcnn.model as modellib\n",
    "from mrcnn import visualize\n",
    "from mrcnn.model import log\n",
    "\n",
    "%matplotlib inline \n",
    "\n",
    "# Directory to save logs and trained model\n",
    "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
    "\n",
    "# Local path to trained weights file\n",
    "COCO_MODEL_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_coco.h5\")\n",
    "# Download COCO trained weights from Releases if needed\n",
    "if not os.path.exists(COCO_MODEL_PATH):\n",
    "    utils.download_trained_weights(COCO_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Configurations:\n",
      "BACKBONE                       resnet101\n",
      "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
      "BATCH_SIZE                     8\n",
      "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
      "COMPUTE_BACKBONE_SHAPE         None\n",
      "DETECTION_MAX_INSTANCES        100\n",
      "DETECTION_MIN_CONFIDENCE       0.7\n",
      "DETECTION_NMS_THRESHOLD        0.3\n",
      "FPN_CLASSIF_FC_LAYERS_SIZE     1024\n",
      "GPU_COUNT                      1\n",
      "GRADIENT_CLIP_NORM             5.0\n",
      "IMAGES_PER_GPU                 8\n",
      "IMAGE_CHANNEL_COUNT            3\n",
      "IMAGE_MAX_DIM                  128\n",
      "IMAGE_META_SIZE                16\n",
      "IMAGE_MIN_DIM                  128\n",
      "IMAGE_MIN_SCALE                0\n",
      "IMAGE_RESIZE_MODE              square\n",
      "IMAGE_SHAPE                    [128 128   3]\n",
      "LEARNING_MOMENTUM              0.9\n",
      "LEARNING_RATE                  0.001\n",
      "LOSS_WEIGHTS                   {'rpn_class_loss': 1.0, 'rpn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_mask_loss': 1.0}\n",
      "MASK_POOL_SIZE                 14\n",
      "MASK_SHAPE                     [28, 28]\n",
      "MAX_GT_INSTANCES               100\n",
      "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
      "MINI_MASK_SHAPE                (56, 56)\n",
      "NAME                           shapes\n",
      "NUM_CLASSES                    4\n",
      "POOL_SIZE                      7\n",
      "POST_NMS_ROIS_INFERENCE        1000\n",
      "POST_NMS_ROIS_TRAINING         2000\n",
      "PRE_NMS_LIMIT                  6000\n",
      "ROI_POSITIVE_RATIO             0.33\n",
      "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
      "RPN_ANCHOR_SCALES              (8, 16, 32, 64, 128)\n",
      "RPN_ANCHOR_STRIDE              1\n",
      "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
      "RPN_NMS_THRESHOLD              0.7\n",
      "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
      "STEPS_PER_EPOCH                100\n",
      "TOP_DOWN_PYRAMID_SIZE          256\n",
      "TRAIN_BN                       False\n",
      "TRAIN_ROIS_PER_IMAGE           32\n",
      "USE_MINI_MASK                  True\n",
      "USE_RPN_ROIS                   True\n",
      "VALIDATION_STEPS               5\n",
      "WEIGHT_DECAY                   0.0001\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class ShapesConfig(Config):\n",
    "    \"\"\"Configuration for training on the toy shapes dataset.\n",
    "    Derives from the base Config class and overrides values specific\n",
    "    to the toy shapes dataset.\n",
    "    \"\"\"\n",
    "    # Give the configuration a recognizable name\n",
    "    NAME = \"shapes\"\n",
    "\n",
    "    # Train on 1 GPU and 8 images per GPU. We can put multiple images on each\n",
    "    # GPU because the images are small. Batch size is 8 (GPUs * images/GPU).\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 8\n",
    "\n",
    "    # Number of classes (including background)\n",
    "    NUM_CLASSES = 1 + 3  # background + 3 shapes\n",
    "\n",
    "    # Use small images for faster training. Set the limits of the small side\n",
    "    # the large side, and that determines the image shape.\n",
    "    IMAGE_MIN_DIM = 128\n",
    "    IMAGE_MAX_DIM = 128\n",
    "\n",
    "    # Use smaller anchors because our image and objects are small\n",
    "    RPN_ANCHOR_SCALES = (8, 16, 32, 64, 128)  # anchor side in pixels\n",
    "\n",
    "    # Reduce training ROIs per image because the images are small and have\n",
    "    # few objects. Aim to allow ROI sampling to pick 33% positive ROIs.\n",
    "    TRAIN_ROIS_PER_IMAGE = 32\n",
    "\n",
    "    # Use a small epoch since the data is simple\n",
    "    STEPS_PER_EPOCH = 100\n",
    "\n",
    "    # use small validation steps since the epoch is small\n",
    "    VALIDATION_STEPS = 5\n",
    "    \n",
    "config = ShapesConfig()\n",
    "config.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook Preferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ax(rows=1, cols=1, size=8):\n",
    "    \"\"\"Return a Matplotlib Axes array to be used in\n",
    "    all visualizations in the notebook. Provide a\n",
    "    central point to control graph sizes.\n",
    "    \n",
    "    Change the default size attribute to control the size\n",
    "    of rendered images\n",
    "    \"\"\"\n",
    "    _, ax = plt.subplots(rows, cols, figsize=(size*cols, size*rows))\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "Create a synthetic dataset\n",
    "\n",
    "Extend the Dataset class and add a method to load the shapes dataset, `load_shapes()`, and override the following methods:\n",
    "\n",
    "* load_image()\n",
    "* load_mask()\n",
    "* image_reference()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShapesDataset(utils.Dataset):\n",
    "    \"\"\"Generates the shapes synthetic dataset. The dataset consists of simple\n",
    "    shapes (triangles, squares, circles) placed randomly on a blank surface.\n",
    "    The images are generated on the fly. No file access required.\n",
    "    \"\"\"\n",
    "\n",
    "    def load_shapes(self, count, height, width):\n",
    "        \"\"\"Generate the requested number of synthetic images.\n",
    "        count: number of images to generate.\n",
    "        height, width: the size of the generated images.\n",
    "        \"\"\"\n",
    "        # Add classes\n",
    "        self.add_class(\"shapes\", 1, \"square\")\n",
    "        self.add_class(\"shapes\", 2, \"circle\")\n",
    "        self.add_class(\"shapes\", 3, \"triangle\")\n",
    "\n",
    "        # Add images\n",
    "        # Generate random specifications of images (i.e. color and\n",
    "        # list of shapes sizes and locations). This is more compact than\n",
    "        # actual images. Images are generated on the fly in load_image().\n",
    "        for i in range(count):\n",
    "            bg_color, shapes = self.random_image(height, width)\n",
    "            self.add_image(\"shapes\", image_id=i, path=None,\n",
    "                           width=width, height=height,\n",
    "                           bg_color=bg_color, shapes=shapes)\n",
    "\n",
    "    def load_image(self, image_id):\n",
    "        \"\"\"Generate an image from the specs of the given image ID.\n",
    "        Typically this function loads the image from a file, but\n",
    "        in this case it generates the image on the fly from the\n",
    "        specs in image_info.\n",
    "        \"\"\"\n",
    "        info = self.image_info[image_id]\n",
    "        bg_color = np.array(info['bg_color']).reshape([1, 1, 3])\n",
    "        image = np.ones([info['height'], info['width'], 3], dtype=np.uint8)\n",
    "        image = image * bg_color.astype(np.uint8)\n",
    "        for shape, color, dims in info['shapes']:\n",
    "            image = self.draw_shape(image, shape, dims, color)\n",
    "        return image\n",
    "\n",
    "    def image_reference(self, image_id):\n",
    "        \"\"\"Return the shapes data of the image.\"\"\"\n",
    "        info = self.image_info[image_id]\n",
    "        if info[\"source\"] == \"shapes\":\n",
    "            return info[\"shapes\"]\n",
    "        else:\n",
    "            super(self.__class__).image_reference(self, image_id)\n",
    "\n",
    "    def load_mask(self, image_id):\n",
    "        \"\"\"Generate instance masks for shapes of the given image ID.\n",
    "        \"\"\"\n",
    "        info = self.image_info[image_id]\n",
    "        shapes = info['shapes']\n",
    "        count = len(shapes)\n",
    "        mask = np.zeros([info['height'], info['width'], count], dtype=np.uint8)\n",
    "        for i, (shape, _, dims) in enumerate(info['shapes']):\n",
    "            mask[:, :, i:i+1] = self.draw_shape(mask[:, :, i:i+1].copy(),\n",
    "                                                shape, dims, 1)\n",
    "        # Handle occlusions\n",
    "        occlusion = np.logical_not(mask[:, :, -1]).astype(np.uint8)\n",
    "        for i in range(count-2, -1, -1):\n",
    "            mask[:, :, i] = mask[:, :, i] * occlusion\n",
    "            occlusion = np.logical_and(occlusion, np.logical_not(mask[:, :, i]))\n",
    "        # Map class names to class IDs.\n",
    "        class_ids = np.array([self.class_names.index(s[0]) for s in shapes])\n",
    "        return mask.astype(np.bool), class_ids.astype(np.int32)\n",
    "\n",
    "    def draw_shape(self, image, shape, dims, color):\n",
    "        \"\"\"Draws a shape from the given specs.\"\"\"\n",
    "        # Get the center x, y and the size s\n",
    "        x, y, s = dims\n",
    "        if shape == 'square':\n",
    "            cv2.rectangle(image, (x-s, y-s), (x+s, y+s), color, -1)\n",
    "        elif shape == \"circle\":\n",
    "            cv2.circle(image, (x, y), s, color, -1)\n",
    "        elif shape == \"triangle\":\n",
    "            points = np.array([[(x, y-s),\n",
    "                                (x-s/math.sin(math.radians(60)), y+s),\n",
    "                                (x+s/math.sin(math.radians(60)), y+s),\n",
    "                                ]], dtype=np.int32)\n",
    "            cv2.fillPoly(image, points, color)\n",
    "        return image\n",
    "\n",
    "    def random_shape(self, height, width):\n",
    "        \"\"\"Generates specifications of a random shape that lies within\n",
    "        the given height and width boundaries.\n",
    "        Returns a tuple of three valus:\n",
    "        * The shape name (square, circle, ...)\n",
    "        * Shape color: a tuple of 3 values, RGB.\n",
    "        * Shape dimensions: A tuple of values that define the shape size\n",
    "                            and location. Differs per shape type.\n",
    "        \"\"\"\n",
    "        # Shape\n",
    "        shape = random.choice([\"square\", \"circle\", \"triangle\"])\n",
    "        # Color\n",
    "        color = tuple([random.randint(0, 255) for _ in range(3)])\n",
    "        # Center x, y\n",
    "        buffer = 20\n",
    "        y = random.randint(buffer, height - buffer - 1)\n",
    "        x = random.randint(buffer, width - buffer - 1)\n",
    "        # Size\n",
    "        s = random.randint(buffer, height//4)\n",
    "        return shape, color, (x, y, s)\n",
    "\n",
    "    def random_image(self, height, width):\n",
    "        \"\"\"Creates random specifications of an image with multiple shapes.\n",
    "        Returns the background color of the image and a list of shape\n",
    "        specifications that can be used to draw the image.\n",
    "        \"\"\"\n",
    "        # Pick random background color\n",
    "        bg_color = np.array([random.randint(0, 255) for _ in range(3)])\n",
    "        # Generate a few random shapes and record their\n",
    "        # bounding boxes\n",
    "        shapes = []\n",
    "        boxes = []\n",
    "        N = random.randint(1, 4)\n",
    "        for _ in range(N):\n",
    "            shape, color, dims = self.random_shape(height, width)\n",
    "            shapes.append((shape, color, dims))\n",
    "            x, y, s = dims\n",
    "            boxes.append([y-s, x-s, y+s, x+s])\n",
    "        # Apply non-max suppression wit 0.3 threshold to avoid\n",
    "        # shapes covering each other\n",
    "        keep_ixs = utils.non_max_suppression(np.array(boxes), np.arange(N), 0.3)\n",
    "        shapes = [s for i, s in enumerate(shapes) if i in keep_ixs]\n",
    "        return bg_color, shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training dataset\n",
    "dataset_train = ShapesDataset()\n",
    "dataset_train.load_shapes(500, config.IMAGE_SHAPE[0], config.IMAGE_SHAPE[1])\n",
    "dataset_train.prepare()\n",
    "\n",
    "# Validation dataset\n",
    "dataset_val = ShapesDataset()\n",
    "dataset_val.load_shapes(50, config.IMAGE_SHAPE[0], config.IMAGE_SHAPE[1])\n",
    "dataset_val.prepare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x360 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x360 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x360 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x360 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load and display random samples\n",
    "image_ids = np.random.choice(dataset_train.image_ids, 4)\n",
    "for image_id in image_ids:\n",
    "    image = dataset_train.load_image(image_id)\n",
    "    mask, class_ids = dataset_train.load_mask(image_id)\n",
    "    visualize.display_top_masks(image, mask, class_ids, dataset_train.class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model in training mode\n",
    "model = modellib.MaskRCNN(mode=\"training\", config=config,\n",
    "                          model_dir=MODEL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Which weights to start with?\n",
    "init_with = \"coco\"  # imagenet, coco, or last\n",
    "\n",
    "if init_with == \"imagenet\":\n",
    "    model.load_weights(model.get_imagenet_weights(), by_name=True)\n",
    "elif init_with == \"coco\":\n",
    "    # Load weights trained on MS COCO, but skip layers that\n",
    "    # are different due to the different number of classes\n",
    "    # See README for instructions to download the COCO weights\n",
    "    model.load_weights(COCO_MODEL_PATH, by_name=True,\n",
    "                       exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\", \n",
    "                                \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
    "elif init_with == \"last\":\n",
    "    # Load the last model you trained and continue training\n",
    "    model.load_weights(model.find_last(), by_name=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "Train in two stages:\n",
    "1. Only the heads. Here we're freezing all the backbone layers and training only the randomly initialized layers (i.e. the ones that we didn't use pre-trained weights from MS COCO). To train only the head layers, pass `layers='heads'` to the `train()` function.\n",
    "\n",
    "2. Fine-tune all layers. For this simple example it's not necessary, but we're including it to show the process. Simply pass `layers=\"all` to train all layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting at epoch 0. LR=0.001\n",
      "\n",
      "Checkpoint Path: /Users/alessandrorusso/workspace/university/projektmodul/Mask_RCNN/logs/shapes20181109T1736/mask_rcnn_shapes_{epoch:04d}.h5\n",
      "Selecting layers to train\n",
      "fpn_c5p5               (Conv2D)\n",
      "fpn_c4p4               (Conv2D)\n",
      "fpn_c3p3               (Conv2D)\n",
      "fpn_c2p2               (Conv2D)\n",
      "fpn_p5                 (Conv2D)\n",
      "fpn_p2                 (Conv2D)\n",
      "fpn_p3                 (Conv2D)\n",
      "fpn_p4                 (Conv2D)\n",
      "In model:  rpn_model\n",
      "    rpn_conv_shared        (Conv2D)\n",
      "    rpn_class_raw          (Conv2D)\n",
      "    rpn_bbox_pred          (Conv2D)\n",
      "mrcnn_mask_conv1       (TimeDistributed)\n",
      "mrcnn_mask_bn1         (TimeDistributed)\n",
      "mrcnn_mask_conv2       (TimeDistributed)\n",
      "mrcnn_mask_bn2         (TimeDistributed)\n",
      "mrcnn_class_conv1      (TimeDistributed)\n",
      "mrcnn_class_bn1        (TimeDistributed)\n",
      "mrcnn_mask_conv3       (TimeDistributed)\n",
      "mrcnn_mask_bn3         (TimeDistributed)\n",
      "mrcnn_class_conv2      (TimeDistributed)\n",
      "mrcnn_class_bn2        (TimeDistributed)\n",
      "mrcnn_mask_conv4       (TimeDistributed)\n",
      "mrcnn_mask_bn4         (TimeDistributed)\n",
      "mrcnn_bbox_fc          (TimeDistributed)\n",
      "mrcnn_mask_deconv      (TimeDistributed)\n",
      "mrcnn_class_logits     (TimeDistributed)\n",
      "mrcnn_mask             (TimeDistributed)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alessandrorusso/workspace/university/projektmodul/Mask_RCNN/venv/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:112: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/Users/alessandrorusso/workspace/university/projektmodul/Mask_RCNN/venv/lib/python3.6/site-packages/keras/engine/training_generator.py:47: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\n",
      "  UserWarning('Using a generator with `use_multiprocessing=True`'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      " 75/100 [=====================>........] - ETA: 6:52 - loss: 2.0587 - rpn_class_loss: 0.0327 - rpn_bbox_loss: 0.6550 - mrcnn_class_loss: 0.4456 - mrcnn_bbox_loss: 0.4860 - mrcnn_mask_loss: 0.4395"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-11:\n",
      "Process ForkPoolWorker-7:\n",
      "Process ForkPoolWorker-5:\n",
      "Process ForkPoolWorker-12:\n",
      "Process ForkPoolWorker-9:\n",
      "Process ForkPoolWorker-6:\n",
      "Process ForkPoolWorker-15:\n",
      "Process ForkPoolWorker-4:\n",
      "Process ForkPoolWorker-1:\n",
      "Process ForkPoolWorker-8:\n",
      "Process ForkPoolWorker-2:\n",
      "Process ForkPoolWorker-3:\n",
      "Process ForkPoolWorker-16:\n",
      "Process ForkPoolWorker-10:\n",
      "Process ForkPoolWorker-14:\n",
      "Process ForkPoolWorker-13:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/Cellar/python/3.6.5/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/local/Cellar/python/3.6.5/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/Cellar/python/3.6.5/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/Cellar/python/3.6.5/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/local/Cellar/python/3.6.5/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/local/Cellar/python/3.6.5/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/local/Cellar/python/3.6.5/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/local/Cellar/python/3.6.5/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/local/Cellar/python/3.6.5/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/local/Cellar/python/3.6.5/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/local/Cellar/python/3.6.5/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/local/Cellar/python/3.6.5/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/local/Cellar/python/3.6.5/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/local/Cellar/python/3.6.5/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/Cellar/python/3.6.5/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/Cellar/python/3.6.5/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/local/Cellar/python/3.6.5/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/local/Cellar/python/3.6.5/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/Cellar/python/3.6.5/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/Cellar/python/3.6.5/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/Cellar/python/3.6.5/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/local/Cellar/python/3.6.5/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/Cellar/python/3.6.5/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/Cellar/python/3.6.5/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/Cellar/python/3.6.5/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/Cellar/python/3.6.5/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/Cellar/python/3.6.5/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/Cellar/python/3.6.5/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/Cellar/python/3.6.5/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/local/Cellar/python/3.6.5/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/Cellar/python/3.6.5/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/Cellar/python/3.6.5/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/local/Cellar/python/3.6.5/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/Cellar/python/3.6.5/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/local/Cellar/python/3.6.5/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/local/Cellar/python/3.6.5/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/local/Cellar/python/3.6.5/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/local/Cellar/python/3.6.5/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/local/Cellar/python/3.6.5/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/Cellar/python/3.6.5/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/local/Cellar/python/3.6.5/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/local/Cellar/python/3.6.5/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/local/Cellar/python/3.6.5/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/usr/local/Cellar/python/3.6.5/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/local/Cellar/python/3.6.5/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/local/Cellar/python/3.6.5/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/local/Cellar/python/3.6.5/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/local/Cellar/python/3.6.5/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/local/Cellar/python/3.6.5/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/local/Cellar/python/3.6.5/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/local/Cellar/python/3.6.5/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/local/Cellar/python/3.6.5/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/local/Cellar/python/3.6.5/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/local/Cellar/python/3.6.5/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/local/Cellar/python/3.6.5/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/local/Cellar/python/3.6.5/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/local/Cellar/python/3.6.5/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/usr/local/Cellar/python/3.6.5/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/local/Cellar/python/3.6.5/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/local/Cellar/python/3.6.5/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/local/Cellar/python/3.6.5/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/local/Cellar/python/3.6.5/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/usr/local/Cellar/python/3.6.5/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/local/Cellar/python/3.6.5/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/local/Cellar/python/3.6.5/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/local/Cellar/python/3.6.5/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/local/Cellar/python/3.6.5/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/local/Cellar/python/3.6.5/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/local/Cellar/python/3.6.5/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/local/Cellar/python/3.6.5/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/local/Cellar/python/3.6.5/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/local/Cellar/python/3.6.5/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/local/Cellar/python/3.6.5/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/local/Cellar/python/3.6.5/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/usr/local/Cellar/python/3.6.5/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/local/Cellar/python/3.6.5/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/local/Cellar/python/3.6.5/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/local/Cellar/python/3.6.5/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/local/Cellar/python/3.6.5/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/local/Cellar/python/3.6.5/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/local/Cellar/python/3.6.5/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/local/Cellar/python/3.6.5/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/local/Cellar/python/3.6.5/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/local/Cellar/python/3.6.5/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-83fb3ae74319>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m             \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLEARNING_RATE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m             layers='heads')\n\u001b[0m",
      "\u001b[0;32m~/workspace/university/projektmodul/Mask_RCNN/venv/lib/python3.6/site-packages/mask_rcnn-2.1-py3.6.egg/mrcnn/model.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, train_dataset, val_dataset, learning_rate, epochs, layers, augmentation, custom_callbacks, no_augmentation_sources)\u001b[0m\n\u001b[1;32m   2373\u001b[0m             \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2374\u001b[0m             \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2375\u001b[0;31m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2376\u001b[0m         )\n\u001b[1;32m   2377\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/university/projektmodul/Mask_RCNN/venv/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/university/projektmodul/Mask_RCNN/venv/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/university/projektmodul/Mask_RCNN/venv/lib/python3.6/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/university/projektmodul/Mask_RCNN/venv/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/university/projektmodul/Mask_RCNN/venv/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/university/projektmodul/Mask_RCNN/venv/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/university/projektmodul/Mask_RCNN/venv/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train the head branches\n",
    "# Passing layers=\"heads\" freezes all layers except the head\n",
    "# layers. You can also pass a regular expression to select\n",
    "# which layers to train by name pattern.\n",
    "model.train(dataset_train, dataset_val, \n",
    "            learning_rate=config.LEARNING_RATE, \n",
    "            epochs=1, \n",
    "            layers='heads')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Fine tune all layers\n",
    "# Passing layers=\"all\" trains all layers. You can also \n",
    "# pass a regular expression to select which layers to\n",
    "# train by name pattern.\n",
    "model.train(dataset_train, dataset_val, \n",
    "            learning_rate=config.LEARNING_RATE / 10,\n",
    "            epochs=2, \n",
    "            layers=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save weights\n",
    "# Typically not needed because callbacks save after every epoch\n",
    "# Uncomment to save manually\n",
    "model_path = os.path.join(MODEL_DIR, \"mask_rcnn_shapes.h5\")\n",
    "model.keras_model.save_weights(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InferenceConfig(ShapesConfig):\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "\n",
    "inference_config = InferenceConfig()\n",
    "\n",
    "# Recreate the model in inference mode\n",
    "model = modellib.MaskRCNN(mode=\"inference\", \n",
    "                          config=inference_config,\n",
    "                          model_dir=MODEL_DIR)\n",
    "\n",
    "# Get path to saved weights\n",
    "# Either set a specific path or find last trained weights\n",
    "# model_path = os.path.join(ROOT_DIR, \".h5 file name here\")\n",
    "model_path = model.find_last()\n",
    "\n",
    "# Load trained weights\n",
    "print(\"Loading weights from \", model_path)\n",
    "model.load_weights(model_path, by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on a random image\n",
    "image_id = random.choice(dataset_val.image_ids)\n",
    "original_image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
    "    modellib.load_image_gt(dataset_val, inference_config, \n",
    "                           image_id, use_mini_mask=False)\n",
    "\n",
    "log(\"original_image\", original_image)\n",
    "log(\"image_meta\", image_meta)\n",
    "log(\"gt_class_id\", gt_class_id)\n",
    "log(\"gt_bbox\", gt_bbox)\n",
    "log(\"gt_mask\", gt_mask)\n",
    "\n",
    "visualize.display_instances(original_image, gt_bbox, gt_mask, gt_class_id, \n",
    "                            dataset_train.class_names, figsize=(8, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.detect([original_image], verbose=1)\n",
    "\n",
    "r = results[0]\n",
    "visualize.display_instances(original_image, r['rois'], r['masks'], r['class_ids'], \n",
    "                            dataset_val.class_names, r['scores'], ax=get_ax())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mAP:  0.95\n"
     ]
    }
   ],
   "source": [
    "# Compute VOC-Style mAP @ IoU=0.5\n",
    "# Running on 10 images. Increase for better accuracy.\n",
    "image_ids = np.random.choice(dataset_val.image_ids, 10)\n",
    "APs = []\n",
    "for image_id in image_ids:\n",
    "    # Load image and ground truth data\n",
    "    image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
    "        modellib.load_image_gt(dataset_val, inference_config,\n",
    "                               image_id, use_mini_mask=False)\n",
    "    molded_images = np.expand_dims(modellib.mold_image(image, inference_config), 0)\n",
    "    # Run object detection\n",
    "    results = model.detect([image], verbose=0)\n",
    "    r = results[0]\n",
    "    # Compute AP\n",
    "    AP, precisions, recalls, overlaps =\\\n",
    "        utils.compute_ap(gt_bbox, gt_class_id, gt_mask,\n",
    "                         r[\"rois\"], r[\"class_ids\"], r[\"scores\"], r['masks'])\n",
    "    APs.append(AP)\n",
    "    \n",
    "print(\"mAP: \", np.mean(APs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
